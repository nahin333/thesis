{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/isic2018\n",
      "/kaggle/input/isic2018/ISIC2018_Task1-2_Validation_Input\n",
      "/kaggle/input/isic2018/ISIC2018_Task1-2_Validation_Input/ISIC2018_Task1-2_Validation_Input\n",
      "/kaggle/input/isic2018/isic2018_task1-2_training_input\n",
      "/kaggle/input/isic2018/isic2018_task1-2_training_input/ISIC2018_Task1-2_Training_Input\n",
      "/kaggle/input/isic2018/isic2018_task1-2_test_input\n",
      "/kaggle/input/isic2018/isic2018_task1-2_test_input/ISIC2018_Task1-2_Test_Input\n",
      "/kaggle/input/isic2018/ISIC2018_Task1-2_Test_Input\n",
      "/kaggle/input/isic2018/ISIC2018_Task1-2_Test_Input/ISIC2018_Task1-2_Test_Input\n",
      "/kaggle/input/isic2018/ISIC2018_Task1_Training_GroundTruth\n",
      "/kaggle/input/isic2018/ISIC2018_Task1_Training_GroundTruth/ISIC2018_Task1_Training_GroundTruth\n",
      "/kaggle/input/isic2018/isic2018_task1_training_groundtruth\n",
      "/kaggle/input/isic2018/isic2018_task1_training_groundtruth/ISIC2018_Task1_Training_GroundTruth\n",
      "/kaggle/input/isic2018/isic2018_task1-2_validation_input\n",
      "/kaggle/input/isic2018/isic2018_task1-2_validation_input/ISIC2018_Task1-2_Validation_Input\n",
      "/kaggle/input/isic2018/ISIC2018_Task1-2_Training_Input\n",
      "/kaggle/input/isic2018/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ISIC 2018\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "Reading ISIC 2018 finished\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import scipy.io as sio\n",
    "import scipy.misc as sc\n",
    "from imageio import imread\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Parameters\n",
    "height = 256\n",
    "width  = 256\n",
    "channels = 3\n",
    "Dataset_add = '/kaggle/input/isic2018/isic2018_task1-2_training_input'\n",
    "Tr_add = 'ISIC2018_Task1-2_Training_Input'\n",
    "\n",
    "Tr_list = glob.glob(Dataset_add+'/'+Tr_add+'/*.jpg')\n",
    "\n",
    "# It contains 2594 training samples\n",
    "Data_train_2018    = np.zeros([2594, height, width, channels])\n",
    "Label_train_2018   = np.zeros([2594, height, width])\n",
    "\n",
    "print('Reading ISIC 2018')\n",
    "for idx in range(len(Tr_list)):\n",
    "    if (idx+1)%50 == 0:\n",
    "        print(idx+1)\n",
    "    img = cv2.imread(Tr_list[idx])\n",
    "    img = np.double(cv2.resize(img,(width,height),interpolation=cv2.INTER_LINEAR))\n",
    "    #img = np.double(sc.imresize(img, [height, width, channels], interp='bilinear', mode = 'RGB'))\n",
    "    Data_train_2018[idx, :,:,:] = img\n",
    "\n",
    "    b = Tr_list[idx]    \n",
    "    a = b[0:len(Dataset_add)]\n",
    "    b = b[len(b)-16: len(b)-4] \n",
    "\n",
    "    add = ('/kaggle/input/isic2018/ISIC2018_Task1_Training_GroundTruth/ISIC2018_Task1_Training_GroundTruth/' + b +'_segmentation.png')    \n",
    "    img2 = cv2.imread(add,0)\n",
    "    img2 = cv2.resize(img2,(width,height),interpolation=cv2.INTER_LINEAR)\n",
    "    #img2 = np.double(sc.imresize(img2, [height, width], interp='bilinear'))\n",
    "    Label_train_2018[idx, :,:] = img2    \n",
    "         \n",
    "print('Reading ISIC 2018 finished')\n",
    "\n",
    "Train_img      = Data_train_2018[0:1815,:,:,:]\n",
    "Validation_img = Data_train_2018[1815:1815+259,:,:,:]\n",
    "Test_img       = Data_train_2018[2274:2594,:,:,:]\n",
    "\n",
    "Train_mask      = Label_train_2018[0:1815,:,:]\n",
    "Validation_mask = Label_train_2018[1815:1815+259,:,:]\n",
    "Test_mask       = Label_train_2018[2274:2594,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "\n",
    "def unet(input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dtype='float32')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop4))\n",
    "    merge6 = concatenate([drop3,up6], axis = 3)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv2,up7], axis = 3)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv1,up8], axis = 3)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
    "\n",
    "    model = Model(input = inputs, output = conv9)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC18 Dataset loaded\n",
      "dataset Normalized\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard,ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "import pickle\n",
    "\n",
    "# ===== normalize over the dataset \n",
    "def dataset_normalized(imgs):\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs-imgs_mean)/imgs_std\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_normalized[i] = ((imgs_normalized[i] - np.min(imgs_normalized[i])) / (np.max(imgs_normalized[i])-np.min(imgs_normalized[i])))*255\n",
    "    return imgs_normalized\n",
    "       \n",
    "    \n",
    "####################################  Load Data #####################################\n",
    "tr_data = Train_img\n",
    "te_data = Test_img\n",
    "val_data = Validation_img\n",
    "\n",
    "tr_mask = Train_mask\n",
    "te_mask = Test_mask\n",
    "val_mask = Validation_mask\n",
    "\n",
    "tr_mask    = np.expand_dims(tr_mask, axis=3)\n",
    "te_mask    = np.expand_dims(te_mask, axis=3)\n",
    "val_mask   = np.expand_dims(val_mask, axis=3)\n",
    "\n",
    "print('ISIC18 Dataset loaded')\n",
    "\n",
    "tr_data   = dataset_normalized(tr_data)\n",
    "te_data   = dataset_normalized(te_data)\n",
    "val_data  = dataset_normalized(val_data)\n",
    "\n",
    "tr_mask   = tr_mask /255.\n",
    "te_mask   = te_mask /255.\n",
    "val_mask  = val_mask /255.\n",
    "\n",
    "print('dataset Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 512)  1049088     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 768)  0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 256 262400      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 384 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 128 442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 128 147584      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 1)  3           conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,091,461\n",
      "Trainable params: 9,091,461\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training\n",
      "Train on 1815 samples, validate on 259 samples\n",
      "Epoch 1/30\n",
      "1815/1815 [==============================] - 78s 43ms/step - loss: 0.7040 - accuracy: 0.7851 - val_loss: 0.6875 - val_accuracy: 0.7587\n",
      "Epoch 2/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6839 - accuracy: 0.7853 - val_loss: 0.6820 - val_accuracy: 0.7587\n",
      "Epoch 3/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6779 - accuracy: 0.7853 - val_loss: 0.6767 - val_accuracy: 0.7587\n",
      "Epoch 4/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6722 - accuracy: 0.7853 - val_loss: 0.6717 - val_accuracy: 0.7587\n",
      "Epoch 5/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6666 - accuracy: 0.7853 - val_loss: 0.6667 - val_accuracy: 0.7587\n",
      "Epoch 6/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6611 - accuracy: 0.7853 - val_loss: 0.6619 - val_accuracy: 0.7587\n",
      "Epoch 7/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6558 - accuracy: 0.7853 - val_loss: 0.6572 - val_accuracy: 0.7587\n",
      "Epoch 8/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6507 - accuracy: 0.7853 - val_loss: 0.6527 - val_accuracy: 0.7587\n",
      "Epoch 9/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6457 - accuracy: 0.7853 - val_loss: 0.6483 - val_accuracy: 0.7587\n",
      "Epoch 10/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6413 - accuracy: 0.7853 - val_loss: 0.6440 - val_accuracy: 0.7587\n",
      "Epoch 11/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6361 - accuracy: 0.7853 - val_loss: 0.6399 - val_accuracy: 0.7587\n",
      "Epoch 12/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6315 - accuracy: 0.7853 - val_loss: 0.6359 - val_accuracy: 0.7587\n",
      "Epoch 13/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6270 - accuracy: 0.7853 - val_loss: 0.6320 - val_accuracy: 0.7587\n",
      "Epoch 14/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6227 - accuracy: 0.7853 - val_loss: 0.6283 - val_accuracy: 0.7587\n",
      "Epoch 15/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6184 - accuracy: 0.7853 - val_loss: 0.6246 - val_accuracy: 0.7587\n",
      "Epoch 16/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6143 - accuracy: 0.7853 - val_loss: 0.6211 - val_accuracy: 0.7587\n",
      "Epoch 17/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6103 - accuracy: 0.7853 - val_loss: 0.6177 - val_accuracy: 0.7587\n",
      "Epoch 18/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6064 - accuracy: 0.7853 - val_loss: 0.6143 - val_accuracy: 0.7587\n",
      "Epoch 19/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.6026 - accuracy: 0.7853 - val_loss: 0.6111 - val_accuracy: 0.7587\n",
      "Epoch 20/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5990 - accuracy: 0.7853 - val_loss: 0.6080 - val_accuracy: 0.7587\n",
      "Epoch 21/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5954 - accuracy: 0.7853 - val_loss: 0.6050 - val_accuracy: 0.7587\n",
      "Epoch 22/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5920 - accuracy: 0.7853 - val_loss: 0.6021 - val_accuracy: 0.7587\n",
      "Epoch 23/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5886 - accuracy: 0.7853 - val_loss: 0.5993 - val_accuracy: 0.7587\n",
      "Epoch 24/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5853 - accuracy: 0.7853 - val_loss: 0.5966 - val_accuracy: 0.7587\n",
      "Epoch 25/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5822 - accuracy: 0.7853 - val_loss: 0.5940 - val_accuracy: 0.7587\n",
      "Epoch 26/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5792 - accuracy: 0.7853 - val_loss: 0.5915 - val_accuracy: 0.7587\n",
      "Epoch 27/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5762 - accuracy: 0.7853 - val_loss: 0.5891 - val_accuracy: 0.7587\n",
      "Epoch 28/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5734 - accuracy: 0.7853 - val_loss: 0.5868 - val_accuracy: 0.7587\n",
      "Epoch 29/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5706 - accuracy: 0.7853 - val_loss: 0.5846 - val_accuracy: 0.7587\n",
      "Epoch 30/30\n",
      "1815/1815 [==============================] - 69s 38ms/step - loss: 0.5680 - accuracy: 0.7853 - val_loss: 0.5825 - val_accuracy: 0.7587\n",
      "Trained model saved\n"
     ]
    }
   ],
   "source": [
    "model_unet = unet(input_size = (256,256,3))\n",
    "model_unet.summary()\n",
    "\n",
    "print('Training')\n",
    "batch_size = 8\n",
    "nb_epoch = 30\n",
    "\n",
    "\n",
    "mcp_save = ModelCheckpoint('weight_isic18_unet', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "history = model_unet.fit(tr_data,tr_mask,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(val_data, val_mask), callbacks=[mcp_save, reduce_lr_loss] )\n",
    "  \n",
    "print('Trained model saved')\n",
    "with open('hist_isic18_unet', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 4s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "te_data    = Test_img\n",
    "te_mask = Test_mask\n",
    "te_mask  = np.expand_dims(te_mask, axis=3)\n",
    "\n",
    "te_data2  = dataset_normalized(te_data) \n",
    "\n",
    "model_unet = unet()\n",
    "model_unet.load_weights('weight_isic18_unet')\n",
    "predictions = model_unet.predict(te_data, batch_size=8, verbose=1)\n",
    "y_scores = predictions.reshape(predictions.shape[0]*predictions.shape[1]*predictions.shape[2]*predictions.shape[3], 1)\n",
    "y_true = te_mask.reshape(te_mask.shape[0]*te_mask.shape[1]*te_mask.shape[2]*te_mask.shape[3], 1)\n",
    "y_scores = np.where(y_scores>0.5, 1, 0)\n",
    "y_true   = np.where(y_true>0.5, 1, 0)\n",
    "\n",
    "threshold_confusion = 0.5\n",
    "y_pred = np.empty((y_scores.shape[0]))\n",
    "for i in range(y_scores.shape[0]):\n",
    "    if y_scores[i]>=threshold_confusion:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:635: DeprecationWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  'and multiclass classification tasks.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard similarity score: 0.7907237052917481\n"
     ]
    }
   ],
   "source": [
    "jaccard_index = jaccard_similarity_score(y_true,  y_pred,  normalize=True)\n",
    "print (\"\\nJaccard similarity score: \" +str(jaccard_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 score (F-measure): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "F1_score   =  f1_score(y_true,   y_pred,  labels=None,  average='binary',  sample_weight=None)\n",
    "print (\"\\nF1 score (F-measure): \" +str(F1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
