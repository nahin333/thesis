{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/dataset-bcd\n",
      "/kaggle/input/dataset-bcd/output_bcdunet\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train/notMelanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid/notMelanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test/notMelanoma\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.applications import ResNet50\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss', color=\"r\", linestyle = \":\")\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss', color=\"g\" )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc', color=\"b\", linestyle = \":\")\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc', color=\"g\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def print_evaluation(loss_value, accuracy_value):\n",
    "    print ('Loss value: ', loss_value)\n",
    "    print ('Accuracy value: ', accuracy_value)\n",
    "\n",
    "    \n",
    "def print_results(cm):\n",
    "    tp = cm[0][0] \n",
    "    tn = cm[1][1]\n",
    "    fn = cm[0][1]\n",
    "    fp = cm[1][0]\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1_score = ((2*precision*recall) / (recall+precision)) * 100\n",
    "    print(\"Accuracy: %f \\n Sensitivity : %f \\n Specificity: %f \\n F1 Score: %f\" %(accuracy,sensitivity,specificity,f1_score))\n",
    "    \n",
    "\n",
    "def fine_tune_resnet():\n",
    "    resnet_model = ResNet50(include_top=False, weights='imagenet')\n",
    "    x = resnet_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=resnet_model.input, outputs=predictions)\n",
    "   \n",
    "    for layer in model.layers[:159]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[159:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    model.save('the_full_model.h5')\n",
    "    model_json = model.to_json()\n",
    "    with open('model.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "def train_network(model, class_weights, val_steps, callbacks, training_path, validation_path, val_batch_size, train_steps):\n",
    "    \n",
    "\n",
    "    return model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 1,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "\n",
    "def fine_tune_resnet50(train_batches, train_steps, class_weight, valid_batches, val_steps, file_path, callbacks):\n",
    "    \n",
    "    resnet_model = ResNet50(include_top=False, weights='imagenet')\n",
    "    \n",
    "    x = Conv2D(filters = 16, kernel_size = 3 , activation = 'relu', input_shape = (299, 299, 3))\n",
    "    \n",
    "    x = Conv2D(filters = 32, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = Conv2D(filters = 128, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size = 3)\n",
    "    \n",
    "    x = resnet_model.output\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=resnet_model.input, outputs=predictions)\n",
    "   \n",
    "    \n",
    "    model.compile(Adam(lr = 0.000095), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 50,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    for layer in model.layers[:159]: layer.trainable = False\n",
    "    \n",
    "    for layer in model.layers[159:]: layer.trainable = True\n",
    "\n",
    "\n",
    "    model.compile(Adam(lr = 0.000095), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 50,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10682 images belonging to 2 classes.\n",
      "Found 3562 images belonging to 2 classes.\n",
      "Found 3561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'weights.h5'\n",
    "\n",
    "\n",
    "training_path = '/kaggle/input/dataset-bcd/output_bcdunet/train'\n",
    "validation_path = '/kaggle/input/dataset-bcd/output_bcdunet/valid'\n",
    "test_path = '/kaggle/input/dataset-bcd/output_bcdunet/test'\n",
    "\n",
    "num_train_samples = 10682\n",
    "num_val_samples = 3562\n",
    "num_test_samples = 3562\n",
    "\n",
    "# 8, 16, 32, 64, 128\n",
    "train_batch_size = 16\n",
    "val_batch_size = 16\n",
    "test_batch_size = 16\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "test_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "class_weights = {\n",
    "        0: 5.1, # melanoma\n",
    "        1: 1.0 # non-melanoma\n",
    "}\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(training_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = val_batch_size,\n",
    "                                    class_mode = 'categorical')\n",
    "valid_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(validation_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = val_batch_size,\n",
    "                                    class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = test_batch_size,\n",
    "                                    class_mode = 'categorical',\n",
    "                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 4s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "668/668 [==============================] - 185s 277ms/step - loss: 0.5224 - acc: 0.8389 - val_loss: 0.2330 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91353, saving model to weights.h5\n",
      "Epoch 2/50\n",
      "668/668 [==============================] - 163s 244ms/step - loss: 0.4094 - acc: 0.8858 - val_loss: 0.1703 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91353 to 0.93262, saving model to weights.h5\n",
      "Epoch 3/50\n",
      "668/668 [==============================] - 163s 244ms/step - loss: 0.3333 - acc: 0.9043 - val_loss: 0.4712 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93262\n",
      "Epoch 4/50\n",
      "668/668 [==============================] - 163s 243ms/step - loss: 0.2846 - acc: 0.9255 - val_loss: 0.4708 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93262\n",
      "Epoch 5/50\n",
      "668/668 [==============================] - 163s 243ms/step - loss: 0.2490 - acc: 0.9378 - val_loss: 0.1799 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93262\n",
      "Epoch 6/50\n",
      "668/668 [==============================] - 163s 244ms/step - loss: 0.1739 - acc: 0.9605 - val_loss: 0.4869 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93262\n",
      "Epoch 7/50\n",
      "668/668 [==============================] - 162s 243ms/step - loss: 0.1175 - acc: 0.9728 - val_loss: 0.4673 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93262\n",
      "Epoch 8/50\n",
      "668/668 [==============================] - 162s 243ms/step - loss: 0.1025 - acc: 0.9775 - val_loss: 0.2125 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93262\n",
      "Epoch 9/50\n",
      " 68/668 [==>...........................] - ETA: 2:10 - loss: 0.0521 - acc: 0.9917"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n",
    "    \n",
    "        ReduceLROnPlateau(monitor = 'val_acc', factor = 0.5, patience = 10, verbose = 1, mode = 'max', min_lr = 0.0000314159265359),\n",
    "        EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 50, verbose = 1)\n",
    "        ]\n",
    "\n",
    "model, history = fine_tune_resnet50(train_batches, train_steps, class_weights, valid_batches, val_steps, file_path, callbacks)\n",
    "save_model(model, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 22s 101ms/step\n",
      "Accuracy: 0.941870 \n",
      " Sensitivity : 0.911286 \n",
      " Specificity: 0.972472 \n",
      " F1 Score: 94.005213\n",
      "Confusion matrix, without normalization\n",
      "[[1623  158]\n",
      " [  49 1731]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classes MELANOMA, NON-MELANOMA\n",
    "test_labels = test_batches.classes\n",
    "\n",
    "predictions = model.predict_generator(test_batches, steps = val_steps, verbose = 1)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
    "\n",
    "print_results(cm)\n",
    "\n",
    "plot_confusion_matrix(cm, ['melanoma', 'non-melanoma'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
