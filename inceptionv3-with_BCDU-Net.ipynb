{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/dataset-bcd\n",
      "/kaggle/input/dataset-bcd/output_bcdunet\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train/notMelanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid/notMelanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test/notMelanoma\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.applications import InceptionV3\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss', color=\"r\", linestyle = \":\")\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss', color=\"g\" )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc', color=\"b\", linestyle = \":\")\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc', color=\"g\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def print_evaluation(loss_value, accuracy_value):\n",
    "    print ('Loss value: ', loss_value)\n",
    "    print ('Accuracy value: ', accuracy_value)\n",
    "\n",
    "    \n",
    "def print_results(cm):\n",
    "    tp = cm[0][0] \n",
    "    tn = cm[1][1]\n",
    "    fn = cm[0][1]\n",
    "    fp = cm[1][0]\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1_score = ((2*precision*recall) / (recall+precision)) * 100\n",
    "    print(\"Accuracy: %f \\n Sensitivity : %f \\n Specificity: %f \\n F1 Score: %f\" %(accuracy,sensitivity,specificity,f1_score))\n",
    "    \n",
    "\n",
    "def fine_tune_inception():\n",
    "    inception_model = InceptionV3(include_top=False, weights='imagenet')\n",
    "    x = inception_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inception_model.input, outputs=predictions)\n",
    "   \n",
    "    for layer in model.layers[:283]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[283:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    model_json = model.to_json()\n",
    "    with open('model.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "def train_network(model, class_weights, val_steps, callbacks, training_path, validation_path, val_batch_size, train_steps):\n",
    "    \n",
    "\n",
    "    return model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 1,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "\n",
    "def fine_tune_inceptionV3(train_batches, train_steps, class_weight, valid_batches, val_steps, file_path, callbacks):\n",
    "    \n",
    "    inception_model = InceptionV3(include_top=False, weights='imagenet')\n",
    "    \n",
    "    x = Conv2D(filters = 16, kernel_size = 3 , activation = 'relu', input_shape = (299, 299, 3))\n",
    "    \n",
    "    x = Conv2D(filters = 32, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = Conv2D(filters = 128, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size = 3)\n",
    "    \n",
    "    x = inception_model.output\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inception_model.input, outputs=predictions)\n",
    "   \n",
    "    \n",
    "    model.compile(Adam(lr = 0.000095), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 50,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    for layer in model.layers[:283]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[283:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "\n",
    "    model.compile(Adam(lr = 0.000095), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 50,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    return model, history\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10682 images belonging to 2 classes.\n",
      "Found 3562 images belonging to 2 classes.\n",
      "Found 3561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'weights.h5'\n",
    "\n",
    "\n",
    "training_path = '/kaggle/input/dataset-bcd/output_bcdunet/train'\n",
    "validation_path = '/kaggle/input/dataset-bcd/output_bcdunet/valid'\n",
    "test_path = '/kaggle/input/dataset-bcd/output_bcdunet/test'\n",
    "\n",
    "num_train_samples = 10682\n",
    "num_val_samples = 3562\n",
    "num_test_samples = 3562\n",
    "\n",
    "# 8, 16, 32, 64, 128\n",
    "train_batch_size = 16\n",
    "val_batch_size = 16\n",
    "test_batch_size = 16\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "test_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "class_weights = {\n",
    "        0: 5.1, # melanoma\n",
    "        1: 1.0 # non-melanoma\n",
    "}\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(training_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = val_batch_size,\n",
    "                                    class_mode = 'categorical')\n",
    "valid_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(validation_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = val_batch_size,\n",
    "                                    class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = test_batch_size,\n",
    "                                    class_mode = 'categorical',\n",
    "                                    shuffle = False)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 3s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "668/668 [==============================] - 173s 259ms/step - loss: 0.5165 - acc: 0.8308 - val_loss: 0.1795 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93318, saving model to weights.h5\n",
      "Epoch 2/50\n",
      "668/668 [==============================] - 145s 217ms/step - loss: 0.3786 - acc: 0.8996 - val_loss: 0.2395 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93318\n",
      "Epoch 3/50\n",
      "668/668 [==============================] - 143s 214ms/step - loss: 0.3072 - acc: 0.9161 - val_loss: 0.2497 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93318\n",
      "Epoch 4/50\n",
      "668/668 [==============================] - 143s 214ms/step - loss: 0.2611 - acc: 0.9269 - val_loss: 0.1604 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93318 to 0.93992, saving model to weights.h5\n",
      "Epoch 5/50\n",
      "668/668 [==============================] - 142s 213ms/step - loss: 0.2020 - acc: 0.9541 - val_loss: 0.1644 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93992\n",
      "Epoch 6/50\n",
      "668/668 [==============================] - 142s 213ms/step - loss: 0.1504 - acc: 0.9676 - val_loss: 0.1456 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.93992 to 0.94554, saving model to weights.h5\n",
      "Epoch 7/50\n",
      "668/668 [==============================] - 143s 213ms/step - loss: 0.1271 - acc: 0.9728 - val_loss: 1.9930 - val_acc: 0.5803\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94554\n",
      "Epoch 8/50\n",
      "668/668 [==============================] - 142s 212ms/step - loss: 0.1121 - acc: 0.9738 - val_loss: 0.1811 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94554\n",
      "Epoch 9/50\n",
      " 78/668 [==>...........................] - ETA: 1:54 - loss: 0.1047 - acc: 0.9784"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "        ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n",
    "    \n",
    "        ReduceLROnPlateau(monitor = 'val_acc', factor = 0.5, patience = 10, verbose = 1, mode = 'max', min_lr = 0.0000314159265359),\n",
    "        EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 50, verbose = 1)\n",
    "        ]\n",
    "\n",
    "model, history = fine_tune_inceptionV3(train_batches, train_steps, class_weights, valid_batches, val_steps, file_path, callbacks)\n",
    "save_model(model, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 20s 89ms/step\n",
      "Accuracy: 0.942151 \n",
      " Sensitivity : 0.927007 \n",
      " Specificity: 0.957303 \n",
      " F1 Score: 94.127708\n",
      "Confusion matrix, without normalization\n",
      "[[1651  130]\n",
      " [  76 1704]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAEYCAYAAAAOFn7lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecVNX5x/HPd0ExoBRFURHFAhobVexKEkWwYgd7xYb+1KjBFqzRaBJj7wVLQI2iCCiiEVtEmqBiAUSNIEpTVFTq8/vjnF0v687u7N7dnZnd553Xfe3MuXfufXYMz557zrnnyMxwzjlXdUW5DsA55wqdJ1LnnEvJE6lzzqXkidQ551LyROqccyl5InXOuZQ8kbqckvQbSc9JWiTpyRTnOVrSi9UZW65I2l3Sx7mOw2VPPo7UZUPSUcD5wFbA98Bk4FozeyPleY8FzgZ2MbPlqQPNc5IMaGdmM3Idi6s+XiN1FZJ0PvBP4C9AK2Bj4A7goGo4/SbAtPqQRLMhqWGuY3BVYGa++ZZxA5oBPwCHl3NMI0Ki/TJu/wQaxX3dgVnAH4G5wBzgxLjvSmApsCxe42TgCuDRxLnbAgY0jO9PAGYSasWfAkcnyt9IfG4XYDywKP7cJbFvDHA18GY8z4tAywy/W3H8FyXi7w3sC0wDFgKXJI7vBrwFfBuPvQ1YPe57Lf4ui+Pve2Ti/H8CvgIeKS6Ln9k8XqNzfL8hMA/onuv/b/j2y+Y1UleRnYE1gKHlHHMpsBPQEehASCaXJfavT0jIrQnJ8nZJLcxsIKGW+7iZrWlm95cXiKQmwC1ALzNbi5AsJ5dx3NrAiHjsOsA/gBGS1kkcdhRwIrAesDpwQTmXXp/wHbQG/gzcCxwDdAF2By6XtGk8dgVwHtCS8N39ATgTwMz2iMd0iL/v44nzr02onfdLXtjMPiEk2UclNQYeBAaZ2Zhy4nW1zBOpq8g6wHwr/9b7aOAqM5trZvMINc1jE/uXxf3LzGwkoTa2ZRXjWQlsK+k3ZjbHzKaWccx+wHQze8TMlpvZYOAj4IDEMQ+a2TQz+wl4gvBHIJNlhPbgZcAQQpK82cy+j9f/gPAHBDObaGZj43U/A+4G9szidxpoZktiPKsws3uBGcDbwAaEP1wuj3gidRVZALSsoO1uQ+DzxPvPY1nJOUol4h+BNSsbiJktJtwOnw7MkTRC0lZZxFMcU+vE+68qEc8CM1sRXxcnuq8T+38q/ryk9pKGS/pK0neEGnfLcs4NMM/Mfq7gmHuBbYFbzWxJBce6WuaJ1FXkLWAJoV0wky8Jt6XFNo5lVbEYaJx4v35yp5mNMrO9CTWzjwgJpqJ4imOaXcWYKuNOQlztzKwpcAmgCj5T7tAZSWsS2p3vB66ITRcuj3gideUys0WEdsHbJfWW1FjSapJ6SbohHjYYuEzSupJaxuMfreIlJwN7SNpYUjPg4uIdklpJOii2lS4hNBGsLOMcI4H2ko6S1FDSkcDWwPAqxlQZawHfAT/E2vIZpfZ/DWxWyXPeDEwws1MIbb93pY7SVStPpK5CZvZ3whjSywg9xl8A/YFn4iHXABOAd4H3gEmxrCrXGg08Hs81kVWTX1GM40tCT/ae/DpRYWYLgP0JIwUWEHrc9zez+VWJqZIuIHRkfU+oLT9eav8VwCBJ30o6oqKTSToI6Mkvv+f5QGdJR1dbxC41H5DvnHMpeY3UOedS8kTqnHMpeSJ1zrmUPJE651xKPkFCHtNqjU2NmuU6jDqlQ/vWFR/kKmXyOxPnm9m6ac/ToOkmZst/9WBXCftp3igz65n2OjXBE2keU6NmNNru+FyHUaeM+c+1uQ6hzmneuGHpp8iqxJb/RKMtM48I+3ny7RU9IZYznkidc/lBgqIGuY6iSjyROufyhwqz28YTqXMuT3iN1Dnn0lNF87vkJ0+kzrn84G2kzjlXDbyN1Dnn0vAaqXPOpSM8kTrnXDryW3vnnEtFQAOvkTrnXDo+/Mk559LwzibnnEvP20idcy4FH5DvnHPVwNtInXMujcKtkRZmg4Rzru4RoY0001bRx6UHJM2V9H6i7ApJsyVNjtu+iX0XS5oh6WNJ+yTKe8ayGZIGZBO6J1LnXJ6INdJMW8UeAspaiuQmM+sYt5EAkrYG+gDbxM/cIamBpAbA7UAvYGugbzy2XH5r75zLHyl67c3sNUltszz8IGCImS0BPpU0A+gW980ws5kAkobEYz8o72ReI3XO5QelrpFm0l/Su/HWv0Usaw18kThmVizLVF4uT6TOufwhZd6gpaQJia1fFme8E9gc6AjMAf5eE2H7rb1zLi8IKCoqt24338y6VuacZvZ1yfmle4Hh8e1soE3i0I1iGeWUZ+Q1UudcflAFW1VOKW2QeHswUNyjPwzoI6mRpE2BdsA4YDzQTtKmklYndEgNq+g6XiN1zuUJVVQjLf/T0mCgO6EJYBYwEOguqSNgwGfAaQBmNlXSE4ROpOXAWWa2Ip6nPzAKaAA8YGZTK7q2J1LnXN5QiiebzKxvGcX3l3P8tcC1ZZSPBEZW5tqeSJ1z+UGgIn9E1DnnqkwoVY00lzyROufyRpo20lzyROqcyxteI3XOuTS8jdQ559LxNlLnnKsGXiN1zrk0VLhtpIXZReZq3F2XHsbnIy5jwqPnrlJ+xmG7MHnI+Ux87DyuPasXABuv34KFY65m7KBzGDvoHG65qHfJ8Vec1oPpzwxg3stX1mr8+e6s005hi002YOeuHUrKrrnyz+zSrRO77diFgw/oyZwvvwTAzLjoj+fSadst2aVbJya/MylXYde4oqKijFs+y+/oXM48MmIiB533wCple3TejP33+C3djr2ZLkffxD//9VrJvpmzFrDT8bew0/G3cM4Nz5SUj3zjQ3Y/+fZai7tQHHXscfz7mRGrlJ1z3gX8d9w7vPH2RPbptR83XHcNAKNHPc/MGdOZ9N5H3Hzbnfzx/87KRcg1rriNNNOWzzyRujK9OflTFn730ypl/Q7Zib898ipLl60AYN43iys8z7ipX/DVgu9rJMZCtutue9Bi7bVXKWvatGnJ6x8XLy5JHiOHP0efo49FEjt024lFixbx1Zw5tRpvrYi99pm2fOZtpC5rW7Rpya4d2nLlaT34eelyLr51JBM/nAVA2w3X5q1B5/D94p+58u4XeXPKZ7kNtkBdPfAyhvzrUZo2a8Zzz78EwJwvZ9N6o41KjtmwdWvmfDmb9TfYINNpCla+1zwzqVc1UkndJQ2v+EhXloYNili7aWP2OOUOLrltJI9ecxQAXy34jva9r2fn42/hTzeP4KEr+7BW40Y5jrYwXX7lNUyd/hmHH9mXe+6qf00ihVojrVeJ1KUze94inhkTpnOc8MEsVq40WjZvwtJlK1j43Y8AvPPxbGbOXki7jVvmMtSCd3ifo3ju2aEAbLBha2bPmlWy78vZs9lgwwpXvyhI3kZaSyS1lfSRpIckTZP0mKS9JL0pabqkbpKaxPVZxkl6R9JBZZynm6S34v7/Stoylp8g6WlJL8Tz3ZD4TF9J70l6X9JfE+U/SLpR0lRJL8Vzj5E0U9KBibhflzQpbrvUxvdVnZ577QP27LI5EG7zV1+tAfO/XUzL5k0oijWGthuuzRZt1uHTLxfmMtSC9MmM6SWvRw4fRrv2WwLQa7/9GfLYI5gZ48eNpWnTpnX2tr5Qe+0LtY10C+Bw4CTCjNZHAbsBBwKXECZr/Y+ZnSSpOTBO0kulzvERsLuZLZe0F/AX4NC4ryPQCVgCfCzpVmAF8FegC/AN8KKk3mb2DNAkXu9CSUOBa4C9Ccu5DiLMsD0X2NvMfpbUDhgMVGrZhNo06Mo+7N55M1o2b8KMZy/m6vtGM+i5Cdx96WFMePRcli5fwSlXPwnAbh035fJT92bZ8hWsNOPsG57hm9hRde1ZvTiyR0car7EaM569mAeHjefa+0v/p6h/Tj7+aN547VUWLJjP1ltswoDLBjJ61PPMmD4NFRXRps3G3HTLHQD06Lkvo0e9QKdtt6Rx48bcftd9OY6+5uR7zTMTmVmuY6iUuNzqaDNrF98/DIwys8ckbQY8TZjxeo34E2BtYB+gFXCBme0vqQ1wC2GJAQNWM7OtJJ0A7Gpmp8bzP0+Y/HUd4FAzOy6WnwxsY2bnS1oCrGFmJukqYImZXSupCFhoZs0lNQNuIyTpFUB7M2tcxu/XDwiLeq3etMsanc+otu/OwVf/+dU8vi6l5o0bTqzsWkpladSqnbU++uaM+z+9ab9quU5NyO/6cmZLEq9XJt6vJNSyRUh6HeO2sZl9WOocVwOvmNm2wAGExFvW+VdQcc19mf3yF6kkHjMrjgfgPOBroAOhJrp6WScys3vMrKuZddVqv8qzztVZEhQVKeNW8ef1gKS5kt5PlN0YmwLflTQ03qEWN7X9JGly3O5KfKZLbMKbIekWZVFNLtREWpFRwNnFX4CkTmUc04xfVgc8IYtzjgP2lNRSUgOgL/BqJWJqBsyJyfVYwnowzrkSqQfkPwT0LFU2GtjWzLYHpgEXJ/Z9kqhsnZ4ovxM4lXC32q6Mc/5KXU2kVwOrAe9Kmhrfl3YDcJ2kd8iirdjM5gADgFeAKcBEM3u2EjHdARwvaQqwFVDxaHbn6pk0NVIzew1YWKrsRTMrbuIbS1heOSOFVUebmtnYeJf5MNC7vM9AAXY2mdlnwLaJ9ydk2HdaGZ8dA4yJr98C2id2XxbLHyL8ZSv+zP6J14MJnUSlz7tm4vUVZe0zs+nA9oldf/r1b+dcPaZwe1+DTgIeT7zfNFakvgMuM7PXgdbArMQxs2JZuQoukTrn6iYBDRqUm0lbSpqQeH+Pmd2T1bmlSwmdz4/FojnAxma2QFIX4BlJ21QhbMATqXMuj1TQFjq/Kr32cSTO/sAfijuFzWwJv3QKT5T0CeEOdTar3v5vxC99KRnV1TZS51yBSdtrX/Y51RO4CDjQzH5MlK8bO42JwybbATNjX8h3knaKndXHARX2hXiN1DmXJ9I9CippMNCd0AQwCxhI6KVvBIyO5x4be+j3AK6StIwwZPF0MyvuqDqT0E/yG+D5uJXLE6lzLm9UteYJYGZ9yyi+P8OxTwFPZdg3gUSHdjY8kTrn8kPN99rXGE+kzrm8INLVSHPJE6lzLm8U6qQlnkidc/lBXiN1zrlUhLeROudcSlUfL5prnkidc3nD20idcy4FeRupc86lV+dqpJKalvdBM/uu+sNxztVndbFGOpWwllHyNyt+b8DGNRiXc66+qYtPNplZm9oMxDlXv6mAe+2zmkZPUh9Jl8TXG8WJUJ1zrloVSRm3fFZhIpV0G/A7woJtAD8Cd2X+hHPOVV5NzEdaW7Lptd/FzDrHtU0ws4WSylxK2Dnn0sjzfJlRNol0maQiQgcTktYhTITqnHPVKt9rnplk00Z6O2EC1HUlXQm8Afy1RqNyztU7InQ4ZfpfPqswkZrZw4Sliv9GWDP6cDMbUtOBOefqGYkGRZm3ij+uByTNlfR+omxtSaMlTY8/W8RySbpF0gxJ70rqnPjM8fH46ZKOzyb0bBe/awAsA5ZW4jPOOVcpUuYtCw8BPUuVDQBeNrN2wMvxPUAvwoJ37YB+wJ3h+lqbsNbTjkA3YGBx8i1PNr32lwKDgQ0JS5P+S9LFFf5KzjlXCYJUNVIze41w15x0EDAovh4E9E6UP2zBWKC5pA2AfYDRZrbQzL4BRvPr5Pwr2XQ2HQd0Kl7KVNK1wDvAdVl81jnnslYDz9q3ikssA3wFtIqvWwNfJI6bFcsylZcrm0Q6p9RxDWOZc85VG4mKap4tJU1IvL/HzO7J9vxmZpKsygGWo7xJS24iDHlaCEyVNCq+7wGMr4lgnHP1WwX10flm1rWSp/xa0gZmNifeus+N5bOB5GPwG8Wy2UD3UuVjKrpIeTXS4p6vqcCIRPnYik7qnHOVVdxGWs2GAccD18efzybK+0saQuhYWhST7SjgL4kOph5AhX1C5U1acn+K4J1zrnKkVG2kkgYTapMtJc0i9L5fDzwh6WTgc+CIePhIYF9gBuGx9xOh5MnNq/nlrvsqMyvdgfUrFbaRStocuBbYGlijuNzM2mfzyznnXLbSPNlkZn0z7PpDGccacFaG8zwAPFCZa2czJvQh4EFCzbsX8ATweGUu4pxzFRHhWftMWz7LJpE2NrNRAGb2iZldRkiozjlXrQp1Gr1shj8tiZOWfCLpdEKv1lo1G5Zzrr7JYvhT3somkZ4HNAHOIbSVNgNOqsmgnHP1U51b/K6Ymb0dX37PL5M7O+dctRLZPQqaj8obkD+UOAdpWczskBqJyDlXP9XFxe+A22otClemTlu25s3Xr891GHVKix365zoEV44GBZpJyxuQ/3JtBuKcq99EHW4jdc652tKwQGc79kTqnMsLYQLnOl4jldTIzJbUZDDOufqtQYHWSLOZIb+bpPeA6fF9B0m31nhkzrl6JTwiWphPNmWT/28B9gcWAJjZFOB3NRmUc65+aqDMWz7L5ta+yMw+L9V2saKG4nHO1VMqgJpnJtkk0i8kdQNMUgPgbGBazYblnKuPCrWNNJtEegbh9n5j4GvgpVjmnHPVpriNtBBl86z9XKBPLcTinKvPVIdrpJLupYxn7s2sX41E5Jyrt1TR8nflfVbaklUnnd8M+DPQHDgVmBfLLzGzkfEzFwMnE/p9zimee7mysrm1fynxeg3gYFZd99k551IT6Z5sMrOPgY4AsT9nNjCUsB7TTWb2t1WuJ21NuNveBtgQeElSezOrdGd6Nrf2qywrIukR4I3KXsg55ypSjU82/QH4pIwRR0kHAUPig0afSpoBdAPequzFqpL/NwVaVeFzzjmXkWIbaaatkvoAgxPv+0t6V9IDiaWWW7Pq3fWsWFZp2TzZ9I2khXH7FhhNFus8O+dcZVXwZFNLSRMSW5n9NJJWBw4EnoxFdwKbE2775wB/r+64y721V6gTdyC0NQCsjMuYOudctRIV1jznm1nXLE7VC5hkZl8DFP+Eks7z4fHtbKBN4nMb8Uuuq5Ryw45Jc6SZrYibJ1HnXA0RReVsldCXxG29pA0S+w4G3o+vhwF9JDWStCnQDhhXlciz6bWfLKmTmb1TlQs451w2VA3jSCU1AfYGTksU3yCpI2EY52fF+8xsqqQngA+A5cBZVemxh/LXbGpoZsuBTsB4SZ8Aiwk1cDOzzlW5oHPOZZL2ySYzWwysU6os46KdZnYtYXXkVMqrkY4DOhMabZ1zrkaFNtK694ioAMzsk1qKxTlXzxXoo/blJtJ1JZ2faaeZ/aMG4nHO1VNSHVxFFGgArAkpHn51zrlKKNRkU14inWNmV9VaJM65ek3UzRppYf5GzrmCVaB5tNxE+odai8I5V+8J1b0aqZktrM1AnHOuzq9r75xzNUp1eKkR55yrDaJq83rmA0+kzrm84TVS55xLqUDzqCdS51x+qKvjSJ1zrhbJb+2dcy6N0NlUmIm0UDvJXI5M+/hjduzSsWRbb+2m3HrzPwG447Zb6bDtVnTusA2XDLgox5Hmn7sGHs3nL1/HhCcvKSl75PoTGTtkAGOHDOCjEVcydsiAkn0XnNSD958dyJShl7PXzr9d5VxFReKtwX/iqZtPr7X4a5ygqCjzls+8Ruoqpf2WW/L2xMkArFixgs03ac2BvQ/m1TGvMPy5Zxk3cQqNGjVi7ty5OY40/zzy3FjuevxV7rv6uJKyYwc8WPL6+vMPZtEPPwGw1Wbrc/g+nel82LVssG4zRt7Vn+16X8XKlWG1n/5H/Y6PP/2atZqsUbu/RA2T10hdffPKf15m0802Z5NNNuGeu+/kgosG0KhRIwDWW2+9HEeXf96c9AkLF/2Ycf+he3fmiRcmArB/9+15ctQkli5bzudfLuCTL+azw7ZtAWi9XnN67rYNDw79b22EXWuKO5sybVmdQ/pM0nuSJkuaEMvWljRa0vT4s0Usl6RbJM2ISzVXedUPT6Suyp58fAhHHNkXgBnTpvHmG6+z+y47svfv92TC+PE5jq6w7Np5c75e+D2f/G8eAK3Xbcasr74p2T977jdsuF4zAG688FAuvfmZktppXSJl3irhd2bWMbHi6ADgZTNrB7wc30NYbbRd3PoRlm2uknqXSONfrJa5jqPQLV26lBHDh3HIYYcDsHzFchYuXMhrb47lL9ffyDFHHYEvOpu9I3p25ckXJlR4XK/dt2Xuwu9558MvaiGq2lUdNdIMDgIGxdeDgN6J8octGAs0L7XiaNbqXSJ11WPUC8/TsVNnWrVqBUDr1hvR++BDkMQO3bpRVFTE/PnzcxxlYWjQoIiDft+Bf4+aVFI2e94iNlq/Rcn71uu14Mu5i9i542bsv+d2fDTiSh6+/kS679CeB645rqzTFiCV+z+gpaQJia1fGScx4EVJExP7W5nZnPj6K6BVfN0aSP5FmhXLKq3GEqmktpI+lHSvpKmSXpT0G0kdJY2NbRJDE+0VYyT9VdI4SdMk7Z7hvGMk3RS/yA8l7SDp6dj+cU3iuGPiuSZLultSgzLO9Uz8wqcm/6NI+kHStZKmxFhbJX6n/8TYX5a0cSx/SNKd8diZkrpLeiDG91DivHfGuKdKurLavuwceOLxwSW39QAHHNibV8e8AsD0adNYunQpLVt6xT8bv99xS6Z99jWz535bUjZizLscvk9nVl+tIZtsuA5bbLwu49//jD/fOowtel7OVvsN5LgBDzJm/DROuuzhHEZfjQRF5WzAfDPrmtjuKeMsu8UVjnsBZ0naI7nTwm1Std8q1XSNtB1wu5ltA3wLHAo8DPzJzLYH3gMGJo5vaGbdgHNLlZe2NLZ/3AU8C5wFbAucIGkdSb8FjgR2NbOOwArg6DLOc5KZdQG6AudIKl7GtQkw1sw6AK8Bp8byW4FBMfbHgFsS52oB7AycBwwDbgK2AbaLa2oDXBrj3h7YU9L2pQOS1K/4L+68+fPK+QpyZ/HixfznpdEcdPAhJWXHn3gSn86cSZeO23Lc0X2474FBBTslWk0ZdN0JjBn0R9pv0ooZL1zN8b13BuDwfbqUdDIV+3DmVzz14ju889SlDLv9TM69/ok62SaaJMKz9pm2bJjZ7PhzLjAU6AZ8XXzLHn8WDymZDbRJfHyjWFZpNT386VMzmxxfTwQ2B5qb2auxbBDwZOL4pxPHti3nvMPiz/eAqcXVdkkzCV/MbkAXYHz8x/wbfvnyks6RdHB83YaQ+BcAS4HhiVj2jq93BoqzxyPADYlzPWdmJuk94Gszey/GNDX+LpOBI2LNtyGwAbA18G4yoPhX9h6ALl265uW/nCZNmjD76wWrlK2++uo8+PCjOYqoMBx/8UNllvcbWPb3dsP9o7jh/lEZz/f6xOm8PnF6dYSWN9L87ZXUBCgys+/j6x7AVYR8cTxwffz5bPzIMKC/pCHAjsCiRBNApdR0Il2SeL0CaJ7l8SuIsUl6EOgEfGlm+5Y6bmWpa6yMnxOh5nhxpgtJ6g7sBexsZj9KGgMUD8pbZr/0lJTEkmXsZcYkaVPgAmAHM/sm3vLXrUGAzqWUchxpK2BorDw1BP5lZi9IGg88Ielk4HPgiHj8SGBfYAbwI3BiVS9c2wPyFwHfSNrdzF4HjgVeLe8DZlaVX+5l4FlJN5nZXElrA2uZ2eeJY5oB38QkuhWwUxbn/S/Qh1AbPRp4vRIxNQUWA4tim2svYEwlPu9cnVeUIo+a2UygQxnlCyhj6aRYWTqr6lf8RS6ebDoeuEtSY2AmKf4KZGJmH0i6jNB7VwQsI3xhyUT6AnC6pA+Bj4GxWZz6bOBBSRcC86hE7GY2RdI7wEeEnsI3s/2sc/VGgTary8f65a8uXbram29XPLbQZa/FDv1zHUKd8/Pk2ycmBr9X2dbbd7JHhmW+Qe26abNquU5N8GftnXN5o0ArpJ5InXP5QgU7ZM4TqXMubxRoHvVE6pzLD8ITqXPOpVao85F6InXO5Y0040hzyROpcy4/iILttvdE6pzLC8WTlhQiT6TOubxRmGnUE6lzLo/4OFLnnEupQPOoJ1LnXP7wROqccymETvvCzKSeSJ1z+UE+jtQ559Ir0ETqyzE75/JE5oXvshlfKqmNpFckfRBX6v2/WH6FpNlxReHJkvZNfOZiSTMkfSxpn6pG7jVS51xeqIYHm5YDfzSzSZLWAiZKGh333WRmf1vletLWhKWDtgE2BF6S1N7MVlT2wl4jdc7lDUkZt4qY2RwzmxRffw98CLQu5yMHAUPMbImZfUpYBK9bVeL2ROqcyxtS5g1oKWlCYuuX+TxqS1h9+O1Y1F/Su5IekNQilrUmrJ9WbBblJ96MPJE65/JD7LXPtAHzzaxrYrunzNNIawJPAeea2XfAncDmQEdgDvD36g7dE6lzLo+onC2LT0urEZLoY2b2NICZfW1mK8xsJXAvv9y+zwbaJD6+USyrNE+kzrm8EGZ/KrdGWv7nQ0Pq/cCHZvaPRPkGicMOBt6Pr4cBfSQ1krQp0A4YV5XYvdfeOZc3Uk6jtytwLPCepMmx7BKgr6SOgAGfAacBmNlUSU8AHxB6/M+qSo89eCJ1zuWTFHnUzN7IcIaR5XzmWuDaql818ETqnMsL8kdEnXMuPZ+0xDnnUvJp9JxzLiVPpM45l4LIbnKSfOTjSJ1zLiWvkTrn8kah1kg9kTrn8oO8jdQ551IRnkidcy41H0fqnHMp+ZNNzjmXlidS55yrujCNXmFmUplZrmNwGUiaB3ye6ziy1BKYn+sg6pBC+j43MbN1055E0guE3zuT+WbWM+11aoInUlctJE0ws665jqOu8O+zsPiTTc45l5InUuecS8kTqasuZa7o6KrMv88C4m2kzjmXktdInXMuJU+kzjmXkidS55xLyROpywnp14+wlFXmqk/p79e/7+rjidTVOkmy2MspaQtJbQHMzPwfd80o9Z1vAOH7zm1UdYf32ruckfR/wKHAHOBbMzstlsv/kdcMSecBewDfAI8A483sh9xGVfi8RupyQtIxwGFAD+BT4GRJz4DXTGuKpBOBA4Ejge2Ai4EDJDXOaWB1gCdSVyvKSIzTgSOAk4GtgMZAV0lDwW87q0Pxdy6pSFJDwoQgxwFnAguAEcDXYQ60AAANI0lEQVR5wOGSmuYs0DrAE6mrcaXa51pIWtPM3gYWAbsCN5vZUsKt5jbFbXiu6ko1jzQ2s+XA34ClwF5m1tPMbo77t89JkHWIz0fqalwiiQ4A/hBfX2Vmr0uaC+wiaVegHbCbmc3NXbR1Q+I7Pw3YX9IIYCjwPbCupLOBWYS20n+a2Xc5C7YO8BqpqzHJ23lJawPdgNOAwcCzkjoD9wKrAbsBV3kSTUdSUeL17kBf4EFgP+BUYH3gT8DewEXABWb2RQ5CrVO8197ViFK388cAbYD1zOy8WHYScD3Q28z+K2n1eHvvqqjUd74LsAGwhpk9Jml74P8IbdND489mZvZNzgKuQ7xG6mpE4h/0voSazxbAdpKOiknzAeAKYHDsNV6es2DriMR33g/4N3AC8HdJG5nZu8A/gM5Ab0IlypNoNfEaqasxkk4h9MyfYmb/k3Qm0B4YB/zbzJZKamZmi3IaaB0iaU/gFOBiM5sl6WpgL+DI+N9gK2CRmc3JaaB1jNdIXbUpY4jTF4R/xIfG94OAacDvgYNimXdypFBqiFMTwvCmrQi1f5nZ5cCLwIuxZvqRJ9Hq5732rlqUap/bklDrGRU7PF6UNMfMhkgaRBiC8xr4eNE0Sg1xWsvMFsXe+KsITy99CUwxs4GSluL/3muM39q7aiXpj8ABhNV13wbuBtYlDv42s4dzGF6dFJtMehOGMo0DbiK0h/4EPGVmE3IYXr3gf6FctZHUETiKMJRpG0LHxoVAf+B44I745NJiM1uZs0DrEEmHEJ4OO4nQVDcEWIvQwXcP0EvSe2a2JHdR1n2eSF2VlTG5SDPCLf1PwARJ3wG9gD3NbLikV8xscU6CrdueNrMpAJJ2IrSJPkZ4lt48idY872xyVVL6sc9Y/AbwraRzAMxsGqGdbou4/6daD7QOyTCRyzLgiPgsPXFI0xSguZnNMbOvajPG+sprpK7SSiXRs4B9JU0HriM8RdNT0r+BlwhP0PwdwG/nq67Ud3464XHaSXGw/e7A5Pjf4rdAF8CfEKtF3tnkqiy2z50BXAoMBN4FHgcWEtrtfgaGmdnUnAVZx0jqTviD9RywEbCY0B56NrAZsDFwuX/ntcsTqauS2LH0D0L73G2SmhF6i78B7jCzT3IaYB0k6ThCx93JZvaepB0IDzwY8Bcz+1bSama2LKeB1kPeRuqyUkb73DLgA6C3pM7x6aRzCM/U95O0Wm3HWNeU8Z2PB7Yl1PYxs/GEO4AmwCWSGuCP2uaE10hdhcqYDGMeoQ2uiJA81wPuM7N34tM1Tf3pmXRKfedtgOVmNic+4vlf4AYzuz7u7wTM9pmzcscTqatQ8T9qSf0JjyC+AOwEHA2sJMy43g74W5wcw1UTSRcC3YHmwL1m9pCk9sArwP1m9udcxucCv7V3GcWaUPEaSgcQ5rb8PWH+0DbAy8DqhKeXpuI9xdUqTvqyj5ntR1gg8M+Szo7DyvYG+kpaJ8OwKFeLPJG6MklaB7hNYaVPgA+BwwkLp3Uzs98S5rR8jfA46I0+ZjEdSZ0lPZVoX/6O0N58HuGPV3/gYkmXmtkHwNZmtsDnK8g9T6Quk8WERwx3l9TPzGaY2ZfA1oTeeYAJwETCmkA+RjQlM5sEtAAejc0pTxDWteoOnGlmIwkPPXSK0w9673ye8DZSt4pSnRyNgN8Rxoq+aGa3S7oRaEQYK9oLONDMvs5ZwHVAvDUvMrMV8f0Iwhjcw81spaT74vv3gf2B/mb2Wa7idb/mNVJXolQSXR9Y08xeAO4E9pbUF7ga+B/QCujnSTSd4u/czFZIagUQ20QNKL7NvxtYQujcG+BJNP94jdT9iqQLgD2BdYCngAeAHQkL1400s3tzGF6dJOkMQkfeR8A4M3su1kwXEAbgL1NYxvqHnAbqyuQ1UrcKSb0J654fAMwgLI/8DeG5+QeB3yUmKXHVINb0jwIuIPTG/x5KaqabEP6QQWi3dnnIa6T1nKSiZEeRpL0JYxa3IswrekBcW2kLM5shqYlPhVd9FJZPPhOYDGwKHAvsF2ugTc3sO0ltzJdMzms++1M9V5xEY030R2BXoANhSNN+ZrY8TovXQ9LhnkTTKT2Ha+xMmkuYP/RTM+sejzsbaCrpL55E858n0nqqVMdSH8KQpnuBfQgdSf8GDpTUlrCsb984YbNLIfGdH0p4GuxfhEc+XwDmStoM2Jkw4/0xPka0MHgbaT1UKoluTOgh3i0+bvgXwtjFroRn6LcmLOXr07KlkHz6SNIxhGkH2wJPx59PEoY43Ut48OE4/84Lh7eR1jOlkug5hCE1axGmxHvUzH6Ot/m3AofEGYZcCmUMK/sdMD62OZ9L6GD6q5m9JmkNADP7OXcRu8ryW/t6JvEPujeh1nkscAqwHbCTpDfM7Jn4D3pB7iKtG0ol0XMJEzD/TFhh9SQz+6ekFcCNki40s9dyGK6rIr+1r4cktQZuAZbFCTD+THiu+1DC8KaGZjbEzGbmMs66IJFEdyOsqtqD0EvfSNKV8ZhbCUOcPstRmC4lT6T1kJnNBs4lLNXbN95GXkmYrHkfwoxOrppI2pzwdFgjYBbwFnAbsHl85BYzu9vM/pe7KF0afmtfT5nZ05KWANdJwswGS7oIaGFmP+Y6vrrEzD6RNJAwCXYPYDjh1n414DhJLc1sfi5jdOl4Iq3HzGyEpJXAPZKWm9mThNnvXTWJA+4t/uES4emlImAYYSancd6xVPg8kdZzZva8pJMAX6wupdKD7aOi+FBDZ+BVwppKAwlLhxTP8uQKnCdSh5mNznUMha5U73xbYImZzYlJdFfgPuAMM3s2LlL3fu6iddXNx5E6l1KpJHo+YZXPGcD7ZnappOuAN81seC7jdDXHa6TOpZRIojsShjjtTxj58Iikn8zs4ri/IbDCH/use3z4k3MpKehAeLxzKfA/M/sYOAw4QNKdAGa23JNo3eSJ1LkqSD47H2e4nwL8jTARyU6SVovjQvsAW0laz1f7rLu8jdS5FCQdTUiec4FHgf0IMzddBYyN84o2NLPlOQzT1TCvkTpXRZLOIjw7/w2wJTAqboOAGwlzGeBJtO7zzibnslTcO5/opd8OOMfMxsX9lwA3mNkpkpoBs3MZr6s9XiN1LgulBtu3i6t7bkRYc77YcOK/KTO73Z+drz88kTpXgVLjRPsDIwkTYE8BzolPhkGoobaV1Nw7luoXv7V3rgKJJHogsD1hhqweQFPC6qrXSOpEmLD5SDP7NlexutzwXnvnshDncH0LeMnMTpLUiDB/axugBXAPsMjMfDLseshv7Z3LQmIO156S+pjZEmAIYbaslcBCT6L1l9/aO5elMuZwHSLpIaCJmX2f4/BcDnkida4SypjD9d+AJ9F6zttInasCSXsDn/i6Vg48kTrnXGre2eSccyl5InXOuZQ8kTrnXEqeSJ1zLiVPpM45l5InUlejJK2QNFnS+5KelNQ4xbm6SxoeXx8oaUA5xzaXdGYVrnGFpAuyLS91zEOSDqvEtdpK8tVE6wBPpK6m/WRmHc1sW8J6Rqcnd8b1jir9/0MzG2Zm15dzSHOg0onUuarwROpq0+vAFrEm9rGkhwnru7eR1EPSW5ImxZrrmgCSekr6SNIk4JDiE0k6QdJt8XUrSUMlTYnbLsD1wOaxNnxjPO5CSeMlvSvpysS5LpU0TdIbhJnuyyXp1HieKZKeKlXL3kvShHi+/ePxDSTdmLj2aWm/SJdfPJG6WhGXIu4FvBeL2gF3mNk2wGLgMmAvM+sMTADOl7QGYWXOA4AuwPoZTn8L8KqZdSAshzwVGEB48qijmV0oqUe8ZjegI9BF0h6SuhAWqOsI7AvskMWv87SZ7RCv9yFhHftibeM19gPuir/DyYSZoXaI5z9V0qZZXMcVCH/W3tW030iaHF+/DtwPbAh8bmZjY/lOwNbAm3E+5NUJU9ZtBXxqZtMBJD0K9CvjGr8HjgMwsxXAIkktSh3TI27vxPdrEhLrWsBQM/sxXmNYFr/TtpKuITQfrElYp6nYE2a2EpguaWb8HXoA2yfaT5vFa0/L4lquAHgidTXtJzPrmCyIyXJxsggYbWZ9Sx23yudSEnCdmd1d6hrnVuFcDwG9zWyKpBNYdbmR0s9cW7z22WaWTLhIaluFa7s85Lf2Lh+MBXaVtAWApCaS2gMfEZbu2Dwe1zfD518GzoifbRAXnvueUNssNgo4KdH22lrSesBrQG9Jv5G0FqEZoSJrAXPiuk1Hl9p3uKSiGPNmwMfx2mfE45HUXlKTLK7jCoTXSF3Omdm8WLMbHGeeB7jMzKZJ6geMkPQjoWlgrTJO8X+Eae1OBlYAZ5jZW5LejMOLno/tpL8F3oo14h+AY8xskqTHCesvzQXGZxHy5cDbhEmd3y4V0/+AcYRlSE43s58l3UdoO50U13KaB/TO7ttxhcBnf3LOuZT81t4551LyROqccyl5InXOuZQ8kTrnXEqeSJ1zLiVPpM45l5InUuecS+n/AaJnJYeBdry+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classes MELANOMA, NON-MELANOMA\n",
    "test_labels = test_batches.classes\n",
    "\n",
    "predictions = model.predict_generator(test_batches, steps = val_steps, verbose = 1)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
    "\n",
    "print_results(cm)\n",
    "\n",
    "plot_confusion_matrix(cm, ['melanoma', 'non-melanoma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
