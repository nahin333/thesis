{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/dataset-bcd\n",
      "/kaggle/input/dataset-bcd/output_bcdunet\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/valid/notMelanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/train/notMelanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test/melanoma\n",
      "/kaggle/input/dataset-bcd/output_bcdunet/test/notMelanoma\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.applications import Xception\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss', color=\"r\", linestyle = \":\")\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss', color=\"g\" )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc', color=\"b\", linestyle = \":\")\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc', color=\"g\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def print_evaluation(loss_value, accuracy_value):\n",
    "    print ('Loss value: ', loss_value)\n",
    "    print ('Accuracy value: ', accuracy_value)\n",
    "\n",
    "    \n",
    "def print_results(cm):\n",
    "    tp = cm[0][0] \n",
    "    tn = cm[1][1]\n",
    "    fn = cm[0][1]\n",
    "    fp = cm[1][0]\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1_score = ((2*precision*recall) / (recall+precision)) * 100\n",
    "    print(\"Accuracy: %f \\n Sensitivity : %f \\n Specificity: %f \\n F1 Score: %f\" %(accuracy,sensitivity,specificity,f1_score))\n",
    "    \n",
    "\n",
    "def fine_tune_xception():\n",
    "    xception_model = Xception(include_top=False, weights='imagenet')\n",
    "    x = xception_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=xception_model.input, outputs=predictions)\n",
    "   \n",
    "    for layer in model.layers[:120]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[120:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    model_json = model.to_json()\n",
    "    with open('model.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "def train_network(model, class_weights, val_steps, callbacks, training_path, validation_path, val_batch_size, train_steps):\n",
    "    \n",
    "\n",
    "    return model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 1,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "\n",
    "def fine_tune_xception_f(train_batches, train_steps, class_weight, valid_batches, val_steps, file_path, callbacks):\n",
    "    \n",
    "    xception_model = Xception(include_top=False, weights='imagenet')\n",
    "    \n",
    "    x = Conv2D(filters = 16, kernel_size = 3 , activation = 'relu', input_shape = (299, 299, 3))\n",
    "    \n",
    "    x = Conv2D(filters = 32, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = Conv2D(filters = 128, kernel_size = 3 , activation = 'relu')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size = 3)\n",
    "    \n",
    "    x = xception_model.output\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=xception_model.input, outputs=predictions)\n",
    "   \n",
    "    \n",
    "    model.compile(Adam(lr = 0.000095), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 50,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    for layer in model.layers[:120]: layer.trainable = False\n",
    "        \n",
    "    for layer in model.layers[120:]: layer.trainable = True\n",
    "\n",
    "\n",
    "    model.compile(Adam(lr = 0.000095), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch = train_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              validation_data = valid_batches,\n",
    "                              validation_steps = val_steps,\n",
    "                              epochs = 50,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    return model, history\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10682 images belonging to 2 classes.\n",
      "Found 3562 images belonging to 2 classes.\n",
      "Found 3561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'weights.h5'\n",
    "\n",
    "\n",
    "training_path = '/kaggle/input/dataset-bcd/output_bcdunet/train'\n",
    "validation_path = '/kaggle/input/dataset-bcd/output_bcdunet/valid'\n",
    "test_path = '/kaggle/input/dataset-bcd/output_bcdunet/test'\n",
    "\n",
    "num_train_samples = 10682\n",
    "num_val_samples = 3562\n",
    "num_test_samples = 3562\n",
    "\n",
    "# 8, 16, 32, 64, 128\n",
    "train_batch_size = 16\n",
    "val_batch_size = 16\n",
    "test_batch_size = 16\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "test_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "class_weights = {\n",
    "        0: 5.1, # melanoma\n",
    "        1: 1.0 # non-melanoma\n",
    "}\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(training_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = val_batch_size,\n",
    "                                    class_mode = 'categorical')\n",
    "valid_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(validation_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = val_batch_size,\n",
    "                                    class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path,\n",
    "                                    target_size = (299, 299),\n",
    "                                    batch_size = test_batch_size,\n",
    "                                    class_mode = 'categorical',\n",
    "                                    shuffle = False)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "668/668 [==============================] - 312s 467ms/step - loss: 0.4859 - acc: 0.8464 - val_loss: 0.1574 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94694, saving model to weights.h5\n",
      "Epoch 2/50\n",
      "668/668 [==============================] - 293s 438ms/step - loss: 0.3198 - acc: 0.9082 - val_loss: 0.2177 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94694\n",
      "Epoch 3/50\n",
      "668/668 [==============================] - 292s 437ms/step - loss: 0.2263 - acc: 0.9449 - val_loss: 0.1340 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94694 to 0.95031, saving model to weights.h5\n",
      "Epoch 4/50\n",
      "668/668 [==============================] - 293s 438ms/step - loss: 0.1414 - acc: 0.9680 - val_loss: 0.2302 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95031\n",
      "Epoch 5/50\n",
      "668/668 [==============================] - 292s 437ms/step - loss: 0.1049 - acc: 0.9747 - val_loss: 0.1696 - val_acc: 0.9363\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95031\n",
      "Epoch 6/50\n",
      "668/668 [==============================] - 292s 438ms/step - loss: 0.0629 - acc: 0.9863 - val_loss: 0.2596 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95031\n",
      "Epoch 7/50\n",
      "668/668 [==============================] - 292s 437ms/step - loss: 0.0540 - acc: 0.9886 - val_loss: 0.2165 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95031\n",
      "Epoch 8/50\n",
      "668/668 [==============================] - 292s 438ms/step - loss: 0.0658 - acc: 0.9844 - val_loss: 0.1686 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95031\n",
      "Epoch 9/50\n",
      " 78/668 [==>...........................] - ETA: 4:01 - loss: 0.0645 - acc: 0.9856"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "        ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n",
    "    \n",
    "        ReduceLROnPlateau(monitor = 'val_acc', factor = 0.5, patience = 10, verbose = 1, mode = 'max', min_lr = 0.0000314159265359),\n",
    "        EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 50, verbose = 1)\n",
    "        ]\n",
    "\n",
    "model, history = fine_tune_xception_f(train_batches, train_steps, class_weights, valid_batches, val_steps, file_path, callbacks)\n",
    "save_model(model, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 24s 108ms/step\n",
      "Accuracy: 0.952261 \n",
      " Sensitivity : 0.928692 \n",
      " Specificity: 0.975843 \n",
      " F1 Score: 95.112133\n",
      "Confusion matrix, without normalization\n",
      "[[1654  127]\n",
      " [  43 1737]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classes MELANOMA, NON-MELANOMA\n",
    "test_labels = test_batches.classes\n",
    "\n",
    "predictions = model.predict_generator(test_batches, steps = val_steps, verbose = 1)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
    "\n",
    "print_results(cm)\n",
    "\n",
    "plot_confusion_matrix(cm, ['melanoma', 'non-melanoma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
